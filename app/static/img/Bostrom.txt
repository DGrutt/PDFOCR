[u'Utilitas, Vol. 15, No. 3 (2003): pp. 308\u2014314\n\nAstronomical Waste: The Opportunity Cost of Delayed\n\nTechnological Development\n\nNICK BOSTROM\n\nOxford University\n\nABSTRACT. With very advanced technology, a very large population of people living\nhappy lives could be sustained in the accessible region of the universe. For every year\nthat development of such technologies and colonization of the universe is delayed, there\nis therefore a corresponding opportunity cost: a potential good, lives worth living, is not\nbeing realized. Given some plausible assumptions, this cost is extremely large. However,\nthe lesson for standard utilitarians is not that we ought to maximize the pace of\ntechnological development, but rather that we ought to maximize its safety, i.e. the\nprobability that colonization will eventually occur. This goal has such high utility that\nstandard utilitarians ought to focus all their efforts on it. Utilitarians of a \u2018person\u2014\naffecting\u2019 stripe should accept a modi\ufb01ed version of this conclusion. Some mixed ethical\nviews, which combine utilitarian considerations with other criteria, will also be\n\ncommitted to a similar bottom line.\n\nI. THE RATE OF LOSS OF POTENTIAL LIVES\n\nAs I write these words, suns are illuminating and heating empty rooms, unused energy is\n\nbeing \ufb02ushed down black holes, and our great common endowment of negentropy is', u'being irreversibly degraded into entropy on a cosmic scale. These are resources that an\nadvanced civilization could have used to create value\u2014structures, such as sentient beings\nliving worthwhile lives.\n\nThe rate of this loss boggles the mind. One recent paper speculates, using loose\ntheoretical considerations based on the rate of increase of entropy, that the loss of\npotential human lives in our own galactic supercluster is at least ~lO46 per century of\ndelayed colonization.1 This estimate assumes that all the lost entropy could have been\nused for productive purposes, although no currently known technological mechanisms are\neven remotely capable of doing that. Since the estimate is meant to be a lower bound, this\nradically unconservative assumption is undesirable.\n\nWe can, however, get a lower bound more straightforwardly by simply counting\nthe number or stars in our galactic supercluster and multiplying this number with the\namount of computing power that the resources of each star could be used to generate\nusing technologies for whose feasibility a strong case has already been made. We can\nthen divide this total with the estimated amount of computing power needed to simulate\none human life.\n\nAs a rough approximation, let us say the Virgo Supercluster contains 1013 stars.\nOne estimate of the computing power extractable from a star and with an associated\nplanet\u2014sized computational structure, using advanced molecular nanotechnologyz, is 1042\noperations per second.3 A typical estimate of the human brain\u2019s processing power is\nroughly 1017 operations per second or less.4 Not much more seems to be needed to\nsimulate the relevant parts of the environment in sufficient detail to enable the simulated\n\nminds to have experiences indistinguishable from typical current human experiences.5', u'Given these estimates, it follows that the potential for approximately 1038 human lives is\nlost every century that colonization of our local supercluster is delayed; or equivalently,\nabout 1029 potential human lives per second.\n\nWhile this estimate is conservative in that it assumes only computational\nmechanisms whose implementation has been at least outlined in the literature, it is useful\nto have an even more conservative estimate that does not assume a non\u2014biological\ninstantiation of the potential persons. Suppose that about 1010 biological humans could be\nsustained around an average star. Then the Virgo Supercluster could contain 1023\nbiological humans. This corresponds to a loss of potential of over 1013 potential human\nlives per second of delayed colonization.\n\nWhat matters for present purposes is not the exact numbers but the fact that they\nare huge. Even with the most conservative estimate, assuming a biological\nimplementation of all persons, the potential for over ten trillion potential human beings is\n\nlost for every second of postponement of colonization of our supercluster.6\n\nII. THE OPPORTUNITY COST OF DELAYED COLONIZATION\nFrom a utilitarian perspective, this huge loss of potential human lives constitutes a\ncorrespondingly huge loss of potential value. I am assuming here that the human lives\nthat could have been created would have been worthwhile ones. Since it is commonly\nsupposed that even current human lives are typically worthwhile, this is a weak\nassumption. Any civilization advanced enough to colonize the local supercluster would\nlikely also have the ability to establish at least the minimally favorable conditions\n\nrequired for future lives to be worth living.', u'The effect on total value, then, seems greater for actions that accelerate\ntechnological development than for practically any other possible action. Advancing\ntechnology (or its enabling factors, such as economic productivity) even by such a tiny\namount that it leads to colonization of the local supercluster just one second earlier than\nwould otherwise have happened amounts to bringing about more than 1029 human lives\n(or 1013 human lives if we use the most conservative lower bound) that would not\notherwise have existed. Few other philanthropic causes could hope to mach that level of\nutilitarian payoff.\n\nUtilitarians are not the only ones who should strongly oppose astronomical waste.\nThere are many views about what has value that would concur with the assessment that\nthe current rate of wastage constitutes an enormous loss of potential value. For example,\nwe can take a thicker conception of human welfare than commonly supposed by\nutilitarians (whether of a hedonistic, experientialist, or desire\u2014satisfactionist bent), such as\na conception that locates value also in human flourishing, meaningful relationships, noble\ncharacter, individual expression, aesthetic appreciation, and so forth. So long as the\nevaluation function is aggregative (does not count one person\u2019 s welfare for less just\nbecause there are many other persons in existence who also enjoy happy lives) and is not\nrelativized to a particular point in time (no time\u2014discounting), the conclusion will hold.\n\nThese conditions can be relaxed further. Even if the welfare function is not\nperfectly aggregative (perhaps because one component of the good is diversity, the\nmarginal rate of production of which might decline with increasing population size), it\n\ncan still yield a similar bottom line provided only that at least some significant', u'component of the good is sufficiently aggregative. Similarly, some degree of time\u2014\n\ndiscounting future goods could be accommodated without changing the conclusion.7\n\nIII. THE CHIEF GOAL FOR UTILITARIAN S SHOULD BE TO REDUCE\n\nEXISTENTIAL RISK\n\nIn light of the above discussion, it may seem as if a utilitarian ought to focus her efforts\non accelerating technological development. The payoff from even a very slight success in\nthis endeavor is so enormous that it dwarfs that of almost any other activity. We appear to\nhave a utilitarian argument for the greatest possible urgency of technological\ndevelopment.\n\nHowever, the true lesson is a different one. If what we are concerned with is\n(something like) maximizing the expected number of worthwhile lives that we will\ncreate, then in addition to the opportunity cost of delayed colonization, we have to take\ninto account the risk of failure to colonize at all. We might fall victim to an existential\nrisk, one where an adverse outcome would either annihilate Earth\u2014originating intelligent\nlife or permanently and drastically curtail its potential.8 Because the lifespan of galaxies\nis measured in billions of years, whereas the time\u2014scale of any delays that we could\nrealistically affect would rather be measured in years or decades, the consideration of risk\ntrumps the consideration of opportunity cost. For example, a single percentage point of\nreduction of existential risks would be worth (from a utilitarian expected utility point\u2014of\u2014\nview) a delay of over 10 million years.\n\nTherefore, if our actions have even the slightest effect on the probability of\n\neventual colonization, this will outweigh their effect on when colonization takes place.', u'For standard utilitarians, priority number one, two, three and four should consequently be\nto reduce existential risk. The utilitarian imperative \u2018Maximize expected aggregate\n\nutility!\u2019 can be simpli\ufb01ed to the maxim \u2018Minimize existential riskI\u2019.\n\nIV. IMPLICATIONS FOR AGGREGATIVE PERSON\u2014AFFECTING VIEWS\n\nThe argument above presupposes that our concern is to maximize the total amount of\nwell\u2014being. Suppose instead that we adopt a \u2018person\u2014affecting\u2019 version of utilitarianism,\naccording to which our obligations are primarily towards currently existing persons and\nto those persons that will come to exist.9 On such a person\u2014affecting View, human\nextinction would be bad only because it makes past or ongoing lives worse, not because it\nconstitutes a loss of potential worthwhile lives. What ought someone who embraces this\ndoctrine do? Should he emphasize speed or safety, or something else?\n\nTo answer this, we need to consider some further matters. Suppose one thinks that\nthe probability is negligible that any existing person will survive long enough to get to\nuse a signi\ufb01cant portion of the accessible astronomical resources, which, as described in\nopening section of this paper, are gradually going to waste. Then one\u2019s reason for\nminimizing existential risk is that sudden extinction would off cut an average of, say, 40\nyears from each of the current (six billion or so) human lives.10 While this would\ncertainly be a large disaster, it is in the same big ballpark as other ongoing human\ntragedies, such as world poverty, hunger and disease. On this assumption, then, a person\u2014\naffecting utilitarian should regard reducing existential risk as a very important but not\ncompletely dominating concern. There would in this case be no easy answer to what he\n\nought to do. Where he ought to focus his efforts would depend on detailed calculations', u'about which area of philanthropic activity he would happen to be best placed to make a\ncontribution to.\n\nArguably, however, we ought to assign a non\u2014negligible probability to some\ncurrent people surviving long enough to reap the benefits of a cosmic diaspora. A so\u2014\ncalled technological \u2018singularity\u2019 might occur in our natural lifetime\u201c, or there could be a\nbreakthrough in life\u2014extension, brought about, perhaps, as result of machine\u2014phase\nnanotechnology that would give us unprecedented control over the biochemical processes\nin our bodies and enable us to halt and reverse the aging process.12 Many leading\ntechnologists and futurist thinkers give a fairly high probability to these developments\nhappening within the next several decades.13 Even if you are skeptical about their\nprognostications, you should consider the poor track record of technological forecasting.\nIn view of the well\u2014established unreliability of many such forecasts, it would seem\nunwarranted to be so confident in one\u2019s prediction that the requisite breakthroughs will\nnot occur in our time as to give the hypothesis that they will a probability of less than,\nsay, 1%.\n\nThe expected utility of a 1% chance of realizing an astronomically large good\ncould still be astronomical. But just how good would it be for (some substantial subset of)\ncurrently living people to get access to astronomical amounts of resources? The answer is\nnot obvious. On the one hand, one might re\ufb02ect that in today\u2019s world, the marginal utility\nfor an individual of material resources declines quite rapidly ones his basic needs have\nbeen met. Bill Gate\u2019s level of well\u2014being does not seem to dramatically exceed that of\nmany a person of much more modest means. On the other hand, advanced technologies of\n\nthe sorts that would most likely be deployed by the time we could colonize the local', u'supercluster may well provide new ways of converting resources into well\u2014being. In\nparticular, material resources could be used to greatly expand our mental capacities and\nto indefinitely prolong our subjective lifespan. And it is by no means clear that the\nmarginal utility of extended healthspan and increased mental powers must be sharply\ndeclining above some level. If there is no such decline in marginal utility, we have to\nconclude that the expected utility to current individuals14 of successful colonization of\nour supercluster is astronomically great, and this conclusion holds even if one gives a\nfairly low probability to that outcome. A long shot it may be, but for an expected utility\nmaximizer, the benefit of living for perhaps billions of subjective years with greatly\nexpanded capacities under fantastically favorable conditions could more than make up for\nthe remote prospects of success.\n\nNow, if these assumptions are made, what follows about how a person\u2014affecting\nutilitarian should act? Clearly, avoiding existential calamities is important, not just\nbecause it would truncate the natural lifespan of six billion or so people, but also \u2014 and\ngiven the assumptions this is an even weightier consideration \u2014 because it would\nextinguish the chance that current people have of reaping the enormous bene\ufb01ts of\neventual colonization. However, by contrast to the total utilitarian, the person\u2014affecting\nutilitarian would have to balance this goal with another equally important desideratum,\nnamely that of maximizing the chances of current people surviving to bene\ufb01t from the\ncolonization. For the person\u2014affecting utilitarian, it is not enough that humankind\nsurvives to colonize; it is crucial that extant people be saved. This should lead her to\nemphasize speed of technological development, since the rapid arrival advanced\n\ntechnology would surely be needed to help current people stay alive until the fruits of', u'colonization could be harvested. If the goal of speed con\ufb02icts with the goal of global\nsafety, the total utilitarian should always opt to maximize safety, but the person\u2014affecting\nutilitarian would have to balance the risk of people dying of old age with the risk of them\nsuccumbing in a species\u2014destroying catastrophe. Mixed ethical Views, which also\nincorporate non\u2014utilitarian elements, might or might not yield one of these bottom lines\n\ndepending on the nature of what is added.15\n\n1 M. Cirkovic, \u2018Cosmological Forecast and its Practical Significance\u2019, Journal of Evolution and\n\nTechnology, xii (2002), http://www.jeQress.org/volume12/CosmologicalForecast.pdf.\n\n2 K. E. Drexler, Nanosystems: Molecular Machinery, Manufacturing, and Computation, New York, John\nWiley & Sons, Inc., 1992.\n\n3 R. J. Bradbury, \u2018Matrioshka Brains\u2019, Manuscript, 2002,\nh\ufb01p://www.aeiveos.com/~bradbu_ry/MatrioshkaBrains/MatrioshkaBrains.html\n\n4 N. Bostrom, \u2018How Long Before Superintelligence?\u2019, International Journal of Futures Studies ii (1998);\nR. Kurzweil, The Age of Spiritual Machines: When Computers Exceed Human Intelligence, New York,\nViking, 1999. The lower estimate is in H. Moravec, Robot: Mere Machine to Transcendent Mind, Oxford,\n1999.\n\n5 N. Bostrom, \u2018Are You Living in a Simulation?\u2019, Philosophical Quarterly, liii (211). See also\nh\ufb01p://www.simulation-argurnent.com.\n\n6 The Virgo Supercluster contains only a small part of the colonizable resources in the universe, but it is\nsuf\ufb01ciently big to make the point. The bigger the region we consider, the less certain we can be that\nsigni\ufb01cant parts of it will not have been colonized by a civilization of non-terrestrial origin by the time we\n\ncould get there.', u'7 Utilitarians commonly regard time-discounting as inappropriate in evaluating moral goods (see e.g. R. B.\nBrandt, Morality, Utilitarianism, and Rights, Cambridge, 1992, pp. 23f.). However, it is not clear that\nutilitarians can avoid compromising on this principle in View of the possibility that our actions could\nconceivably have consequences for an in\ufb01nite number of persons (a possibility that we set aside for the\npurposes of this paper).\n\n8 N. Bostrom, \u2018Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards\u2019, Journal of\nEvolution and Technology, ix (2002), h\ufb01p://www.jeQress.org/volume9/risks.html.\n\n9 This formulation of the position is not necessarily the best possible one, but it is simple and will serve for\nthe purposes of this paper.\n\n10 Or whatever the population is likely to be at the time when doomsday would occur.\n\n11 See e.g. V. Vinge, \u2018The Coming Technological Singularity\u2019, Whole Earth Review, Winter issue (1993).\n12 R. A. Freitas Jr., Nanomedicine, Vol. 1, Georgetown, Landes Bioscience, 1999.\n\n13 E.g. Moravec, Kurzweil, and Vinge op. cit.; E. Drexler, Engines of Creation, New York, Anchor Books,\n1986.\n\n14 On the person-affecting view, the relevant factor is not the temporal location of a person per se. In\nprinciple, effects on the well-being of a past or a future person could also be an appropriate target for moral\nconcern. In practice, however, the effect on the well-being of past persons is likely to be relatively small or\neven zero (depending on which conception of well-being one adopts), and the effect (of any action that has\na significant effect on the future) on not-yet\u2014existing persons is very likely to be such that competing\nalternative actions would lead to separate sets of possible persons coming into existence, for example as a\nresult of different sperms fertilizing different eggs, and thus there would typically be no future persons\nwhose level of well-being is affected by our current actions. Our actions might affect which future persons\nthere will be, but on the person-affecting View, such results provide no general moral reasons for action.\nOne exception are fetuses and fertilize eggs, which are not yet persons, but which may become persons in\nthe future, and whose lives our current actions may in\ufb02uence.\n\n15 I\u2019m grateful for comments from John Broome, Milan Cirkovic, Roger Crisp, Robin Hanson, and James\n\nLenman, and for the \ufb01nancial support of a British Academy Postdoctoral Award.\n\n10']