[u'Astronomical Waste: The Opportunity Cost of Del... https://nickbostrom.com/astronomical/waste.html\n\nAstronomical Waste: The Opportunity Cost of Delayed Technological\n\nDevelopment\n\nNICK BOSTROM\nOxford University\n\nhttp://www.nickbostrom.com\n\n[Utilitas Vol. 15, No. 3\n(2003): pp. 308-314]\n\n[\ufb02]\n\nABSTRACT. With very advanced\ntechnology, a very large population of\npeople living happy lives could be\nsustained in the accessible region of the\nuniverse. For every year that\ndevelopment of such technologies and\ncolonization of the universe is delayed,\nthere is therefore an opportunity cost: a\npotential good, lives worth living, is\nnot being realized. Given some\nplausible assumptions, this cost is\nextremely large. However, the lesson\nfor utilitarians is not that we ought to\nmaximize the pace of technological\ndevelopment, but rather that we ought\nto maximize its safety, i.e. the\nprobability that colonization will\neventually occur.\n\nI. THE RATE OF LOSS OF POTENTIAL LIVES\n\nAs I write these words, suns are illuminating and\nheating empty rooms, unused energy is being\n\ufb02ushed down black holes, and our great common\nendowment of negentropy is being irreversibly\ndegraded into entropy on a cosmic scale. These are\nresources that an advanced civilization could have\nused to create value-structures, such as sentient\nbeings living worthwhile lives.\n\nThe rate of this loss boggles the mind. One recent\npaper speculates, using loose theoretical\n\n1 of9 3/1/18, 9:42 PM', u'Astronomical Waste: The Opportunity Cost of Del...\n\nhttps://nickbostrom.com/astronomical/waste.html\n\nconsiderations based on the rate of increase of\nentropy, that the loss of potential human lives in our\n\nown galactic supercluster is at least ~10A46 per\ncentury of delayed colonizationm This estimate\nassumes that all the lost entropy could have been\nused for productive purposes, although no currently\nknown technological mechanisms are even remotely\ncapable of doing that. Since the estimate is meant to\nbe a lower bound, this radically unconservative\n\nassumption is undesirable.\n\nWe can, however, get a lower bound more\nstraightforwardly by simply counting the number or\nstars in our galactic supercluster and multiplying\nthis number with the amount of computing power\nthat the resources of each star could be used to\ngenerate using technologies for whose feasibility a\nstrong case has already been made. We can then\ndivide this total with the estimated amount of\ncomputing power needed to simulate one human\n\nlife.\n\nAs a rough approximation, let us say the Virgo\n\nSupercluster contains 10\n\nA13\n\nstars. One estimate of\n\nthe computing power extractable from a star and\nwith an associated planet-sized computational\nstructure, using advanced molecular\n\nnanotechnologym, is 10A42 operations per\nsecond\ufb02l A typical estimate of the human brain\u2019s\n\nprocessing power is roughly 1\n\n0A17\n\noperations per\n\nsecond or lessJ\ufb02 Not much more seems to be\nneeded to simulate the relevant parts of the\nenvironment in sufficient detail to enable the\nsimulated minds to have experiences\nindistinguishable from typical current human\nexperiences\ufb02 Given these estimates, it follows\n\nthat the potential for approximately 10/\\38 human\nlives is lost every century that colonization of our\nlocal supercluster is delayed; or equivalently, about\n\n10/\\29 potential human lives per second.\n\nWhile this estimate is conservative in that it\nassumes only computational mechanisms whose\nimplementation has been at least outlined in the\nliterature, it is useful to have an even more\nconservative estimate that does not assume a non-\n\n20f9\n\n3/1/18, 9:42 PM', u'Astronomical Waste: The Opportunity Cost of Del...\n\nhttps://nickbostrom.com/astronomical/waste.html\n\nbiological instantiation of the potential persons.\n\nSuppose that about 10/\\10 biological humans could\nbe sustained around an average star. Then the Virgo\n\nSupercluster could contain 10A23 biological\nhumans. This corresponds to a loss of potential\n\nequal to about 10A14 potential human lives per\n\nsecond of delayed colonization.\n\nWhat matters for present purposes is not the exact\nnumbers but the fact that they are huge. Even with\nthe most conservative estimate, assuming a\nbiological implementation of all persons, the\npotential for one hundred trillion potential human\nbeings is lost for every second of postponement of\ncolonization of our supercluster.[\ufb02\n\nII. THE OPPORTUNITY COST OF DELAYED\nCOLONIZATION\n\nFrom a utilitarian perspective, this huge loss of\npotential human lives constitutes a correspondingly\nhuge loss of potential value. I am assuming here\nthat the human lives that could have been created\nwould have been worthwhile ones. Since it is\ncommonly supposed that even current human lives\nare typically worthwhile, this is a weak assumption.\nAny civilization advanced enough to colonize the\nlocal supercluster would likely also have the ability\nto establish at least the minimally favorable\nconditions required for future lives to be worth\n\nliving.\n\nThe effect on total value, then, seems greater for\nactions that accelerate technological development\nthan for practically any other possible action.\nAdvancing technology (or its enabling factors, such\nas economic productivity) even by such a tiny\namount that it leads to colonization of the local\nsupercluster just one second earlier than would\notherwise have happened amounts to bringing about\n\nmore than 10A29 human lives (or 10/\\14 human lives\nif we use the most conservative lower bound) that\nwould not otherwise have existed. Few other\nphilanthropic causes could hope to mach that level\n\nof utilitarian payoff.\n\nUtilitarians are not the only ones who should\n\n30f9\n\n3/1/18, 9:42 PM', u'Astronomical Waste: The Opportunity Cost of Del...\n\nhttps://nickbostrom.com/astronomical/waste.html\n\nstrongly oppose astronomical waste. There are\nmany views about what has value that would concur\nwith the assessment that the current rate of wastage\nconstitutes an enormous loss of potential value. For\nexample, we can take a thicker conception of\nhuman welfare than commonly supposed by\nutilitarians (whether of a hedonistic, experientialist,\nor desire-satisfactionist bent), such as a conception\nthat locates value also in human \ufb02ourishing,\nmeaningful relationships, noble character,\nindividual expression, aesthetic appreciation, and so\nforth. So long as the evaluation function is\naggregative (does not count one person\u2019s welfare\nfor less just because there are many other persons in\nexistence who also enjoy happy lives) and is not\nrelativized to a particular point in time (no time-\ndiscounting), the conclusion will hold.\n\nThese conditions can be relaxed further. Even if the\nwelfare function is not perfectly aggregative\n(perhaps because one component of the good is\ndiversity, the marginal rate of production of which\nmight decline with increasing population size), it\ncan still yield a similar bottom line provided only\nthat at least some significant component of the good\nis sufficiently aggregative. Similarly, some degree\nof time-discounting future goods could be\naccommodated without changing the conclusionm\n\nIII. THE CHIEF GOAL FOR UTILITARIANS\nSHOULD BE TO REDUCE EXISTENTIAL RISK\n\nIn light of the above discussion, it may seem as if a\nutilitarian ought to focus her efforts on accelerating\ntechnological development. The payoff from even a\nvery slight success in this endeavor is so enormous\nthat it dwarfs that of almost any other activity. We\nappear to have a utilitarian argument for the greatest\npossible urgency of technological development.\n\nHowever, the true lesson is a different one. If what\nwe are concerned with is (something like)\nmaximizing the expected number of worthwhile\nlives that we will create, then in addition to the\nopportunity cost of delayed colonization, we have to\ntake into account the risk of failure to colonize at\nall. We might fall victim to an existential risk, one\n\n4of9\n\n3/1/18, 9:42 PM', u'Astronomical Waste: The Opportunity Cost of Del...\n\n50f9\n\nwhere an adverse outcome would either annihilate\nEarth-originating intelligent life or permanently and\ndrastically curtail its potential.ml Because the\nlifespan of galaxies is measured in billions of years,\nwhereas the time-scale of any delays that we could\nrealistically affect would rather be measured in\nyears or decades, the consideration of risk trumps\nthe consideration of opportunity cost. For example,\na single percentage point of reduction of existential\nrisks would be worth (from a utilitarian expected\nutility point-of-view) a delay of over 10 million\nyears.\n\nTherefore, if our actions have even the slightest\neffect on the probability of eventual colonization,\nthis will outweigh their effect on when colonization\ntakes place. For standard utilitarians, priority\nnumber one, two, three and four should\nconsequently be to reduce existential risk. The\nutilitarian imperative \u201cMaximize expected\naggregate utility!\u201d can be simplified to the maxim\n\u201cMinimize existential riskl\u201d.\n\nIV. IMPLICATIONS FOR AGGREGATIVE\nPERSON-AFFECTING VIEWS\n\nThe argument above presupposes that our concern\nis to maximize the total amount of well-being.\nSuppose instead that we adopt a \u201cperson-affecting\u201d\nversion of utilitarianism, according to which our\nobligations are primarily towards currently existing\npersons and to those persons that will come to\nexist.@ On such a person-affecting view, human\nextinction would be bad only because it makes past\nor ongoing lives worse, not because it constitutes a\nloss of potential worthwhile lives. What ought\nsomeone who embraces this doctrine do? Should he\nemphasize speed or safety, or something else?\n\nTo answer this, we need to consider some further\nmatters. Suppose one thinks that the probability is\nnegligible that any existing person will survive long\nenough to get to use a significant portion of the\naccessible astronomical resources, which, as\ndescribed in opening section of this paper, are\ngradually going to waste. Then one\u2019s reason for\nminimizing existential risk is that sudden extinction\n\nhttps://nickbostrom.com/astronomical/waste.html\n\n3/1/18, 9:42 PM', u'Astronomical Waste: The Opportunity Cost of Del...\n\nhttps://nickbostrom.com/astronomical/waste.html\n\nwould off cut an average of, say, 40 years from each\nof the current (six billion or so) human lives.@\nWhile this would certainly be a large disaster, it is\nin the same big ballpark as other ongoing human\ntragedies, such as world poverty, hunger and\ndisease. On this assumption, then, a person-\naffecting utilitarian should regard reducing\nexistential risk as a very important but not\ncompletely dominating concern. There would in this\ncase be no easy answer to what he ought to do.\nWhere he ought to focus his efforts would depend\non detailed calculations about which area of\nphilanthropic activity he would happen to be best\n\nplaced to make a contribution to.\n\nArguably, however, we ought to assign a non-\nnegligible probability to some current people\nsurviving long enough to reap the benefits of a\ncosmic diaspora. A so-called technological\n\u201csingularity\u201d might occur in our natural\nlifetimelm, or there could be a breakthrough in\nlife-extension, brought about, perhaps, as result of\nmachine-phase nanotechnology that would give us\nunprecedented control over the biochemical\nprocesses in our bodies and enable us to halt and\nreverse the aging process.@ Many leading\ntechnologists and futurist thinkers give a fairly high\nprobability to these developments happening within\nthe next several decadesJ\ufb02 Even if you are\nskeptical about their prognostications, you should\nconsider the poor track record of technological\nforecasting. In view of the well-established\nunreliability of many such forecasts, it would seem\nunwarranted to be so confident in one\u2019s prediction\nthat the requisite breakthroughs will not occur in\nour time as to give the hypothesis that they will a\n\nprobability of less than, say, 1%.\n\nThe expected utility of a 1% chance of realizing an\nastronomically large good could still be\nastronomical. But just how good would it be for\n(some substantial subset of) currently living people\nto get access to astronomical amounts of resources?\nThe answer is not obvious. On the one hand, one\nmight re\ufb02ect that in today\u2019s world, the marginal\nutility for an individual of material resources\ndeclines quite rapidly once his basic needs have\n\n6of9\n\n3/1/18, 9:42 PM', u"Astronomical Waste: The Opportunity Cost of Del...\n\n7of9\n\nbeen met. Bill Gates' level of well-being does not\nseem to dramatically exceed that of many a person\nof much more modest means. On the other hand,\nadvanced technologies of the sorts that would most\nlikely be deployed by the time we could colonize\nthe local supercluster may well provide new ways\nof converting resources into well-being. In\nparticular, material resources could be used to\ngreatly expand our mental capacities and to\nindefinitely prolong our subjective lifespan. And it\nis by no means clear that the marginal utility of\nextended healthspan and increased mental powers\nmust be sharply declining above some level. If there\nis no such decline in marginal utility, we have to\nconclude that the expected utility to current\nindividuals of successful colonization of our\nsupercluster is astronomically great, and this\nconclusion holds even if one gives a fairly low\nprobability to that outcome. A long shot it may be,\nbut for an expected utility maximizer, the benefit of\nliving for perhaps billions of subjective years with\ngreatly expanded capacities under fantastically\nfavorable conditions could more than make up for\nthe remote prospects of success.\n\nNow, if these assumptions are made, what follows\nabout how a person-affecting utilitarian should act?\nClearly, avoiding existential calamities is important,\nnot just because it would truncate the natural\nlifespan of six billion or so people, but also \u2014 and\ngiven the assumptions this is an even weightier\nconsideration \u2014 because it would extinguish the\nchance that current people have of reaping the\nenormous benefits of eventual colonization.\nHowever, by contrast to the total utilitarian, the\nperson-affecting utilitarian would have to balance\nthis goal with another equally important\ndesideratum, namely that of maximizing the\nchances of current people surviving to benefit from\nthe colonization. For the person-affecting utilitarian,\nit is not enough that humankind survives to\ncolonize; it is crucial that extant people be saved.\nThis should lead her to emphasize speed of\ntechnological development, since the rapid arrival\nadvanced technology would surely be needed to\nhelp current people stay alive until the fruits of\ncolonization could be harvested. If the goal of speed\n\nhttps://nickbostrom.com/astronomical/waste.html\n\n3/1/18, 9:42 PM", u'Astronomical Waste: The Opportunity Cost of Del...\n\n80f9\n\ncon\ufb02icts with the goal of global safety, the total\nutilitarian should always opt to maximize safety, but\nthe person-affecting utilitarian would have to\nbalance the risk of people dying of old age with the\nrisk of them succumbing in a species-destroying\ncatastrophe\ufb02l\n\n[11 M. Cirkovic, \u2018Cosmological Forecast and its\nPractical Significance\u2019, Journal of Evolution and\n\nTechnology, xii (2002), http://www.jetpressorg\n\n/volume12/CosmologicalForecast.pdf.\n[21 K. E. Drexler, Nanosystems: Molecular\n\nMachinery, Manufacturing, and Computation, New\nYork, John Wiley & Sons, Inc., 1992.\n\nm R. J. Bradbury, \u2018Matrioshka Brains\u2019,\nManuscript, 2002, http://www.aeiveos.com\nWW\n/MatrioshkaBrains.html\n\n[Al N. Bostrom, \u2018How Long Before\nSuperintelligence?\u2019, International Journal of Futures\nStudies ii (1998); R. Kurzweil, The Age of Spiritual\nMachines: When Computers Exceed Human\nIntelligence, New York, Viking, 1999. The lower\nestimate is in H. Moravec, Robot: Mere Machine to\nTranscendent Mind, Oxford, 1999.\n\n[j N. Bostrom, \u2018Are You Living in a Simulation?\u2019,\nPhilosophical Quarterly, liii (211). See also\nhttp://www.simulation-argument.com.\n\n[Q The Virgo Supercluster contains only a small\npart of the colonizable resources in the universe, but\nit is sufficiently big to make the point. The bigger\nthe region we consider, the less certain we can be\nthat significant parts of it will not have been\ncolonized by a civilization of non-terrestrial origin\nby the time we could get there.\n\n[11 Utilitarians commonly regard time-discounting\nas inappropriate in evaluating moral goods (see e.g.\nR. B. Brandt, Morality, Utilitarianism, and Rights,\nCambridge, 1992, pp. 23f.). However, it is not clear\nthat utilitarians can avoid compromising on this\nprinciple in view of the possibility that our actions\ncould conceivably have consequences for an infinite\nnumber of persons (a possibility that we set aside\nfor the purposes of this paper).\n\nhttps://nickbostrom.com/astronomical/waste.html\n\n3/1/18, 9:42 PM', u'Astronomical Waste: The Opportunity Cost of Del...\n\nhttps://nickbostrom.com/astronomical/waste.html\n\n[Q N. Bostrom, \u2018EXistential Risks: Analyzing\nHuman Extinction Scenarios and Related Hazards\u2019,\nJournal of Evolution and Technology, iX (2002),\nhER1\ufb02MMQLB\ufb02\ufb02\ufb02\ufb01\ufb01\xe9\ufb02gb\ufb02\ufb02ug\ufb01\ufb02\ufb02\ufb02\ufb02\xa7i\ufb02\ufb02\ufb02-\n\n[91 This formulation of the position is not\nnecessarily the best possible one, but it is simple\nand will serve for the purposes of this paper.\n\n[m Or whatever the population is likely to be at\nthe time when doomsday would occur.\n\n[\xa31 See e.g. V. Vinge, \u2018The Coming Technological\nSingularity\u2019, Whole Earth Review, Winter issue\n\n(1993)\n\n[g1 R. A. Freitas Jr., Nanomedicine, Vol. 1,\nGeorgetown, Landes Bioscience, 1999.\n\nEBJ E.g. Moravec, Kurzweil, and Vinge op. cit.; E.\nDrexler, Engines of Creation, New York, Anchor\n\nBooks, 1986.\n\n[E I\u2019m grateful for the financial support of a\nBritish Academy Postdoctoral Award.\n\n90f9\n\n3/1/18, 9:42 PM']